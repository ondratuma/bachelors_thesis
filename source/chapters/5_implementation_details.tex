\chap Implementation
In this chapter, I will describe my implementation and the particular solutions used to comply with decisions made in chapter ~\ref[chapter_implementation_decisions].

\sec Application architecture
The application is split between a server, a frontend, and a robot part.
The Server is a central part of the project, communicating with the frontend and the robots. The robots and the frontend communicate only with the server and are completely independent of each other.
\secc Communication
All communication in the built system is based on an abstract interface built upon \nanomsg. This abstraction greatly simplifies the introduction of new message types and the general process of sending/receiving messages and synchronizing a global state.\br

The main classes used for communication are Messenger\label[messenger]\wlabel{} (asynchronous handler for inbound/outbound messages) and Message (serializable container), providing an easy-to-use interface and abstracting the network layer away from the programmer. The basic hierarchy of used communication classes is illustrated below.
\communicationUml
\break
Server and Frontend each have their own instance of Messenger associated with given Message type, communicating through API defined by a given messenger. In the case of SynchronizedStateMessenger, only the latest version of the synchronized state is publicly available outside of the class.

The asynchronous nature of the communication can be seen in the sequence diagram below.

\communicationSequence

The asynchronous handlers allow both applications to run in the main thread performing latency-sensitive tasks. The current implementation uses a thread per messenger, mainly to eliminate application-wide locking and shared state, but another more optimal approach could be a single static event loop for all the messengers. It would be more efficient but it could also introduce hard to debug bugs where one Messenger instance could affect every other messenger. It was decided to go with the threaded implementation. But the Messenger architecture makes it possible to simply change the implementation if it proves to have additional benefits.\br

During the implementation of the above-mentioned mechanisms, great measures were taken to avoid race conditions. The Messenger has an implementation of Lamport's logical clock, assuring the order of messages for each Message type. This is mainly to prevent the user from updating a state on the server based on a non-actual version.
\label[shared_resources]
\secc Shared resources
Since one part of the application is built using \makefile, and the other part using \cmake, it made sharing code across parts of the application more difficult. The configuration of {\of} only allows one user-defined include directory, so all the shared files have a flat structure in the "{projectRoot}/FleetControl/modules/utils/Comm" directory.
\sec TurtleBot
The software running directly on TurtleBot is based on ROS. Its main purpose is to receive commands from the server and broadcasts its position. 
It acts on the instructions by using the position API provided by the underlying layer described in {~\ref[position_api]}. It also performs translations to and from its grid coordinate system. The robot is the only component that should be aware of its shifted grid relative to the standard cartesian coordinate system beginning in (0, 0).

TurtleBot software is built using CMake.
The sources for the TurtleBot are in the "/src" directory, where the actual code resides in the "/src/agv_package/TurtleBot/" directory.

At runtime, the TurtleBot uses the following ports.
\begitems \style x
    * single port defined in "/robot_definitions.txt" - server commands handling
    * 9980 - position feedback
\enditems
\br

\sec Server
The general idea behind the server architecture is that it should mainly handle the execution of the demonstration, while aggregating data from {\vicon} and robots, and synchronizing them to the frontend. \br
The execution of the demonstration should be guided by the synchronization strategy {\ref[synchronization_strategy]} currently selected.\br\br
The server code resides in the "{projectRoot}/FleetControl/modules/manager" directory. The only other code it touches should be the {Shared resources}~\ref[shared_resources].\br

\secc Vicon
The laboratory is equipped with a {\vicon} motion capture system, monitoring the area spanned by robots completely. The purpose of the system is to provide positions of defined known objects.\br
The system consists of a central server, and high refresh rate motion cameras emplaced on the ceiling of the laboratory around the monitored area. Additional tooling is used to transform the source data from the {\vicon} system into a network stream that can be consumed by other applications running on the local network.\br
The actual usage in the server is then relatively straightforward. Each robot is assigned a name in the {\vicon} system, that is referenced in the file with robot definitions in the root of the project. Afterward, when the {\vicon} system is running, we are able to transform the output data into a continuous stream of data, send it over the network to the Server, filter out only wanted objects, and save the current position provided by {\vicon} for each robot. The final position for each robot is periodically transferred to Frontend primarily to save network bandwidth. But given the high refresh rate of the positioning system, and the relatively low speed of physical robots, the updating period was set to 100ms without any noticeable delay in the user interface.

\secc Network communication
The server is the only component of the application, that is aware of more than one other component. It serves as a central point for all other components. It communicates with the frontend, with each one of the robots and {\vicon}.

The following ports should be used at runtime
\begitems \style x
    * 1 port per robot for command execution
    * 1 port per robot for position feedback
    * 1 port for Vicon
    * 5 ports for Frontend connections
\enditems

\sec GUI
The GUI is implemented using {\of}. The GUI runs a single thread for main logic and event handling, and another one for the GUI application. Communication with the server is directed through the Messenger abstraction, allowing uninterrupted handling of all events that might arise and providing smooth rendering for the application. All synchronous events and rendering happen in the main event loop of {\of}, providing a centralized state for the whole component.
The code resides in "{projectRoot}/FleetControl/modules/app" directory
\fleetControlGui
\break
The GUI, as visualized in ~\ref[fleet_control_user_interface], displays robot positions based on position data from robots, or alternatively from a connection to the {\vicon} system, allowing the user to browse all time steps and show available information about them. It also provides the user with the ability to disable individual agents for a given simulation run and to completely start and stop the simulation run.
\fleetControlAdminPanel
\midinsert
\line{\hsize=.5\hsize \vtop{%
   \clabel[gui_robot_panel]{Robot panel}
   \picw=6cm \cinspic {../assets/images/new_ui_robot_panel.png}
   \caption/f Robot panel
\par}\vtop{%
   \clabel[gui_plan_highlight]{Plan highlight}
   \picw=6cm \cinspic {../assets/images/new_ui_plan_highlight.png}
   \caption/f Plan highlight
\par}}
\endinsert
Most of the settings can be changed in the admin panel {~\ref[fleet_control_admin_panel]} on the left side of the application window.\br
The admin panel allows the user to disable individual robots, which is useful if the battery of the robot died, but the remaining robots are still good enough for demonstration purposes. The system then does not send new commands to the disabled robots. The options may be reset even during a demonstration run, so this option might be used to consistently test the synchronization algorithms, by making a robot blocked, while still being part of the execution plan. Below is the option to change the position provider for showing the robot real-time positions in the user interface. This option does not override the robot's internal positioning system. The default option is Robot, as the {\vicon} startup time is not insignificant, the cameras have a limited lifespan and for the majority of demonstration runs the feedback from robots gives the same information within an acceptable margin of error. The simulation can be started using the "start simulation" button. This also allows the user to disable the simulation again after the start of the execution, preventing the server from sending any new commands to any of the active robots.\br

\sec Coordinate system
\finalGrid
The reference coordinate system used across the system is relative to the output of the solver. All reference, robot, and vicon coordinate systems can be seen on {~\ref[final_grid]} highlighted in blue, purple, and green, respectively. The reference coordinate system starts at the point (0, 0) in the lower-left corner of the demonstration grid just as a convention. The robots have the coordinate system shifted and scaled. The beginning of the Vicon coordinate system can be seen highlighted in green. The robot coordinate system scale is roughly equivalent to the scale of Vicon, meaning that the distance between two neighboring nodes is roughly 0.7m.\br
The translation from Vicon coordinate system to the base one happens on the server right after the reception of Vicon data and no other system component is aware of the different coordinate system used by Vicon.
The translation from base to Robot coordinate system and in reverse happens on the robot and no other system component is aware of the different coordinate system used by the robots.

\label[synchronization_strategy]
\sec Robot synchronization strategies
The solver solves the problem set in discreet time steps. The solution should guarantee that the simulation will be run without collisions. However, that can be quite inefficient, as, in the real world, the speeds of individual robots may differ from the expected ones, and making all robots wait for single a slow robot may lead to a bottleneck in the whole system. It is therefore desirable to be able to break the distinct step barrier. That may, however, break the consistency of the plan, and introduce potential collisions. Once we disable this implicit safeguard, it is necessary to introduce an additional, possibly more efficient solution, that will prevent collisions and enable the simulation to run without inconsistencies.\br
By eliminating the implicit barrier, we are able to dynamically enable and disable multiple synchronization strategies, making the system more modular, and allowing the development of new algorithms and the demonstrator without any modification to existing strategies. Each strategy should act independently on the state of other strategies. \br
Currently, a reimplementation of the original implicit barrier and Action dependency graph strategy are available.
\secc Discreet time step
This synchronization strategy is reintroducing the constraints given by the solver output, keeping all robots in the same time step, until the last one finishes execution. The reintroduction of the implicit barrier as a modular strategy makes it great for testing new planning algorithms, where the original solution of the solver can be inspected without real-world inconsistencies.
\secc Action dependency graph
The second currently implemented approach is to construct an action dependency graph of the nodes, and ensure the correct execution order for actions on given nodes. The algorithm was inspired by the {\uv{Persistent and Robust Execution of MAPF Schedules in Warehouses}\cite[adgPaper] paper. It greatly increases the efficiency, allowing robots to move, until they break the dependency graph. In the original paper, replanning algorithm is also introduced, but it was not implemented here for demonstration purposes, as changing the plan during execution would be quite contrary to the idea of the demonstrator, where we are demonstrating the execution plan itself. It might, however, be quite interesting demonstration on its own. \br
\vfil \break
\secc Demonstration
On the figures {~\ref[adg_step_1]}-{~\ref[adg_step_15]} you can see part of the execution using ADG. The figures are not spaced evenly relative to the simulation time, rather selected to represent significant events during the execution. \br
Before figure {~\ref[adg_step_3]}, the execution is running normally. However, somewhere between {~\ref[adg_step_2]} and {~\ref[adg_step_3]}, the green robot has been delayed. In order to continue execution, the red robot has to wait. This is represented by having the currently waiting robot's grid block highlighted in red, as can be seen in {~\ref[adg_step_3]}.
The red robot continues to wait, until the next node in its desired path is free (from the ADG perspective) {~\ref[adg_step_7]}. Meaning that every robot, who planned to travel through the node before this one already did so. The inverse situation, where robot 3 is blocked by robot 1 can be seen on {~\ref[adg_step_12]}, {~\ref[adg_step_13]}. The rest of the demonstration does not need to avoid any collisions, it is therefore not included in this example. The robots will just return to their initial positions without any unexpected behavior.

\midinsert
\line{\hsize=.3333333333\hsize \vtop{%
        \clabel[adg_step_1]{Step 1}
        \picw=4.7cm \cinspic {../assets/images/new_ui_adg_1.png}
        \caption/f Step 1
   \par}\vtop{%
        \clabel[adg_step_2]{Step 2}
        \picw=4.7cm \cinspic {../assets/images/new_ui_adg_3.png}
        \caption/f Step 2
   \par}\vtop{%
        \clabel[adg_step_3]{Step 3}
        \picw=4.7cm \cinspic {../assets/images/new_ui_adg_4.png}
        \caption/f Step 3
   \par}}
\endinsert
\midinsert
\line{\hsize=.3333333333\hsize \vtop{%
   \clabel[adg_step_4]{Step 4}
   \picw=4.7cm \cinspic {../assets/images/new_ui_adg_5.png}
   \caption/f Step 4
\par}\vtop{%
   \clabel[adg_step_5]{Step 5}
   \picw=4.7cm \cinspic {../assets/images/new_ui_adg_6.png}
   \caption/f Step 5
\par}\vtop{%
   \clabel[adg_step_6]{Step 6}
   \picw=4.7cm \cinspic {../assets/images/new_ui_adg_7.png}
   \caption/f Step 6
\par}}
\endinsert
\midinsert
\line{\hsize=.3333333333\hsize \vtop{%
   \clabel[adg_step_7]{Step 7}
   \picw=4.7cm \cinspic {../assets/images/new_ui_adg_8.png}
   \caption/f Step 7
\par}\vtop{%
   \clabel[adg_step_8]{Step 8}
   \picw=4.7cm \cinspic {../assets/images/new_ui_adg_9.png}
   \caption/f Step 8
\par}\vtop{%
   \clabel[adg_step_9]{Step 9}
   \picw=4.7cm \cinspic {../assets/images/new_ui_adg_10.png}
   \caption/f Step 9
\par}}
\endinsert
\midinsert
\line{\hsize=.3333333333\hsize \vtop{%
   \clabel[adg_step_10]{Step 12}
   \picw=4.7cm \cinspic {../assets/images/new_ui_adg_11.png}
   \caption/f Step 10
\par}\vtop{%
   \clabel[adg_step_11]{Step 11}
   \picw=4.7cm \cinspic {../assets/images/new_ui_adg_12.png}
   \caption/f Step 11
\par}\vtop{%
   \clabel[adg_step_12]{Step 12}
   \picw=4.7cm \cinspic {../assets/images/new_ui_adg_13.png}
   \caption/f Step 12
\par}}
\endinsert
\midinsert
\line{\hsize=.3333333333\hsize \vtop{%
   \clabel[adg_step_13]{Step 13}
   \picw=4.7cm \cinspic {../assets/images/new_ui_adg_14.png}
   \caption/f Step 13
\par}\vtop{%
   \clabel[adg_step_14]{Step 14}
   \picw=4.7cm \cinspic {../assets/images/new_ui_adg_15.png}
   \caption/f Step 15
\par}\vtop{%
   \clabel[adg_step_15]{Step 15}
   \picw=4.7cm \cinspic {../assets/images/new_ui_adg_16.png}
   \caption/f Step 16
\par}}
\endinsert